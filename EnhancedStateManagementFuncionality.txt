# Enhanced State Management for MosaicLLM

State management is a critical aspect of any interactive application, and as MosaicLLM grows, having a structured approach to state will become increasingly important. Let's explore how we could improve state management in your application:

## Current State Management

Currently, MosaicLLM uses Streamlit's session state (`st.session_state`) directly throughout the codebase:

```python
# Scattered throughout components
if "config" not in st.session_state: st.session_state.config = load_config()
if "show_settings" not in st.session_state: st.session_state.show_settings = False
st.session_state.current_chat_id = new_chat_id
st.session_state.chats[chat_id]["title"] = generate_title_with_llm(...)
```

While this works, it has some drawbacks:
- State is accessed and modified from anywhere, making it hard to track changes
- No clear structure to the state data
- No validation or type checking
- Difficult to implement complex state transitions

## Enhanced State Management Approach

Here's how we could implement a more structured state management system:

### 1. State Modules with Domain-Specific Logic

Create dedicated modules for different aspects of state:

**state/chat_state.py**
```python
import streamlit as st
from datetime import datetime
from typing import Dict, List, Any, Optional

def initialize_chat_state():
    """Initialize chat-related state if not already present."""
    if "chats" not in st.session_state:
        st.session_state.chats = {}
    
    if "current_chat_id" not in st.session_state or st.session_state.current_chat_id not in st.session_state.chats:
        ensure_at_least_one_chat()

def ensure_at_least_one_chat():
    """Ensure there is at least one chat available."""
    if not st.session_state.chats:
        first_chat_id = create_new_chat()
        st.session_state.current_chat_id = first_chat_id

def create_new_chat() -> str:
    """Create a new chat and return its ID."""
    chat_id = f"chat_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
    st.session_state.chats[chat_id] = {"title": "New Chat", "messages": []}
    return chat_id

def switch_to_chat(chat_id: str) -> bool:
    """Switch to a different chat by ID. Returns True if successful."""
    if chat_id in st.session_state.chats:
        st.session_state.current_chat_id = chat_id
        st.session_state.stop_streaming = False
        st.session_state.is_generating = False
        st.session_state.uploaded_file_content = None
        st.session_state.uploaded_file_name = None
        return True
    return False

def delete_chat(chat_id: str) -> Optional[str]:
    """Delete a chat and return the ID of the next chat to select."""
    if chat_id not in st.session_state.chats:
        return None
        
    if len(st.session_state.chats) <= 1:
        return None  # Can't delete the last chat
    
    # Find next chat to select
    chat_ids = list(st.session_state.chats.keys())
    current_index = chat_ids.index(chat_id)
    
    next_chat_id = None
    if current_index > 0:
        next_chat_id = chat_ids[current_index - 1]
    elif current_index < len(chat_ids) - 1:
        next_chat_id = chat_ids[current_index + 1]
    
    # Delete the chat
    del st.session_state.chats[chat_id]
    
    return next_chat_id

def add_message(role: str, content: str, **metadata) -> None:
    """Add a message to the current chat."""
    if st.session_state.current_chat_id not in st.session_state.chats:
        ensure_at_least_one_chat()
        
    message = {
        "role": role,
        "content": content,
        **metadata
    }
    
    st.session_state.chats[st.session_state.current_chat_id]["messages"].append(message)

def get_current_chat_messages() -> List[Dict[str, Any]]:
    """Get messages from the current chat."""
    if st.session_state.current_chat_id not in st.session_state.chats:
        ensure_at_least_one_chat()
        
    return st.session_state.chats[st.session_state.current_chat_id]["messages"]

def update_chat_title(chat_id: str, title: str) -> None:
    """Update the title of a specific chat."""
    if chat_id in st.session_state.chats:
        st.session_state.chats[chat_id]["title"] = title
```

**state/ui_state.py**
```python
import streamlit as st

def initialize_ui_state():
    """Initialize UI-related state if not already present."""
    if "show_settings" not in st.session_state:
        st.session_state.show_settings = False
    if "show_token_cost" not in st.session_state:
        st.session_state.show_token_cost = False
    if "show_context_usage" not in st.session_state:
        st.session_state.show_context_usage = False
    if "show_file_uploader" not in st.session_state:
        st.session_state.show_file_uploader = False
    if "needs_rerun" not in st.session_state:
        st.session_state.needs_rerun = False

def toggle_settings():
    """Toggle settings panel visibility."""
    st.session_state.show_settings = not st.session_state.show_settings
    
def toggle_token_cost():
    """Toggle token cost display."""
    st.session_state.show_token_cost = not st.session_state.show_token_cost
    
def toggle_context_usage():
    """Toggle context usage display."""
    st.session_state.show_context_usage = not st.session_state.show_context_usage

def toggle_file_uploader():
    """Toggle file uploader visibility."""
    st.session_state.show_file_uploader = not st.session_state.show_file_uploader
```

**state/llm_state.py**
```python
import streamlit as st
from typing import Dict, Optional

def initialize_llm_state(config):
    """Initialize LLM-related state."""
    if "selected_llm" not in st.session_state:
        available_llms = get_available_llms(config)
        if available_llms:
            st.session_state.selected_llm = available_llms[0]
        else:
            st.session_state.selected_llm = "None"
    
    if "stop_streaming" not in st.session_state:
        st.session_state.stop_streaming = False
        
    if "is_generating" not in st.session_state:
        st.session_state.is_generating = False

def get_available_llms(config) -> list:
    """Get list of available LLM models from config."""
    available_llms = []
    if "llm_models" in config:
        available_llms = list(config["llm_models"].keys())
    return available_llms

def select_llm(llm_name: str) -> bool:
    """Select an LLM by name. Returns True if successful."""
    available_llms = get_available_llms(st.session_state.config)
    if llm_name in available_llms or llm_name == "None":
        st.session_state.selected_llm = llm_name
        return True
    return False

def start_generation():
    """Set state for starting LLM response generation."""
    st.session_state.is_generating = True
    st.session_state.stop_streaming = False
    st.session_state.needs_rerun = True
    
def stop_generation():
    """Set state for stopping LLM response generation."""
    st.session_state.stop_streaming = True
    
def end_generation():
    """Set state for ending LLM response generation."""
    st.session_state.is_generating = False
    st.session_state.stop_streaming = False
    st.session_state.needs_rerun = True
```

**state/file_state.py**
```python
import streamlit as st

def initialize_file_state():
    """Initialize file-related state."""
    if "uploaded_file_content" not in st.session_state:
        st.session_state.uploaded_file_content = None
    if "uploaded_file_name" not in st.session_state:
        st.session_state.uploaded_file_name = None

def set_uploaded_file(file_name: str, file_content: str):
    """Set the uploaded file information."""
    st.session_state.uploaded_file_name = file_name
    st.session_state.uploaded_file_content = file_content
    st.session_state.show_file_uploader = False
    st.session_state.needs_rerun = True
    
def clear_uploaded_file():
    """Clear the uploaded file information."""
    st.session_state.uploaded_file_name = None
    st.session_state.uploaded_file_content = None
    st.session_state.needs_rerun = True

def has_uploaded_file() -> bool:
    """Check if a file is uploaded and ready to send."""
    return (st.session_state.uploaded_file_content is not None and 
            st.session_state.uploaded_file_name is not None)
```

### 2. State Initialization Module

Create a central module to initialize all state:

**state/session_state.py**
```python
import streamlit as st
from state.chat_state import initialize_chat_state
from state.ui_state import initialize_ui_state
from state.llm_state import initialize_llm_state
from state.file_state import initialize_file_state
from utils.file_handler import load_config

def initialize_session_state():
    """Initialize all session state components."""
    # Load config first as other state might depend on it
    if "config" not in st.session_state:
        st.session_state.config = load_config()
    
    # Initialize all state modules
    initialize_chat_state()
    initialize_ui_state()
    initialize_llm_state(st.session_state.config)
    initialize_file_state()
```

### 3. Updated main.py

Now the main.py file becomes much cleaner:

```python
import streamlit as st

# Import state management
from state.session_state import initialize_session_state
from state.chat_state import delete_chat, switch_to_chat
from state.ui_state import toggle_settings

# Import service layer
from services.llm_service import LLMService

# Import UI components
from components.sidebar import render_sidebar
from components.settings_panel import render_settings_panel
from components.chat_window import render_chat_window
from components.input_area import render_input_area
from components.llm_response_handler import handle_llm_response

# Set up page configuration
st.set_page_config(
    layout="wide",
    page_title="MosaicLLM",
    page_icon="üß©"
)

# Initialize all session state
initialize_session_state()

# Initialize LLM service if needed
if "llm_service" not in st.session_state:
    st.session_state.llm_service = LLMService(st.session_state.config)

# Process delete request if present
if st.session_state.get("delete_request"):
    delete_info = st.session_state.pop("delete_request")
    delete_id = delete_info["delete_id"]
    next_id = delete_info["next_id"]
    
    if next_id:
        switch_to_chat(next_id)

# --- UI Rendering ---

# Settings Toggle Button
col1, col2 = st.columns([10, 1])
with col1:
    effective_llm = st.session_state.selected_llm if st.session_state.selected_llm != "None" else "No LLM Selected"
    st.markdown(f"""
        <h1 style="color:#4B6EAF; margin-bottom:0;">
            MosaicLLM Studio <span style="font-size:0.8em; color:#6C757D;">({effective_llm})</span>
        </h1>
        """, 
        unsafe_allow_html=True
    )
with col2:
    if st.button("‚öôÔ∏è", key="settings_toggle", help="Open Settings"):
        toggle_settings()

# Render UI Components
render_settings_panel()
render_sidebar()
render_chat_window()
render_input_area()
handle_llm_response()

# Single rerun point
if st.session_state.needs_rerun:
    st.session_state.needs_rerun = False
    st.rerun()
```

## Benefits of This Approach

1. **Encapsulation**: State logic is encapsulated in dedicated modules
2. **Reusability**: State functions can be reused across components
3. **Maintainability**: Easier to understand and modify state behavior
4. **Type Safety**: Functions provide a typed interface to the state
5. **Validation**: Can add validation logic when updating state
6. **Testing**: State logic can be tested independently of UI
7. **Documentation**: Function signatures and docstrings document state behavior

## Implementation Strategy

To implement this improved state management:

1. Start with the most critical state modules (chat_state.py)
2. Gradually refactor components to use the new state functions
3. Add more state modules as needed
4. Update main.py last, once all components are using the new state functions

This approach allows for incremental improvement without breaking existing functionality, and sets up a solid foundation for future enhancements to MosaicLLM.

Would you like to start implementing this enhanced state management approach, or would you prefer to focus on a different aspect of the refactoring first?